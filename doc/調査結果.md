# 調査結果

Expert を目指すにあたり必要な諸々について簡単に調査した結果をまとめる。

## Kaggle のランク制度と外部評価

### 外部評価

正直 Master 以上でない限り、基本的には「取り組み」レベルでしか評価されなさそう。
逆に Master 以上になると、条件として明記されるようになり、組織側が「弊社には〇人います」といったアピールもするようになるらしい。
ただ、「自然言語処理での Kaggle 受賞歴」、「分析コンペでのメダル獲得経験」などを評価点として明記している組織はある。

### あくまで戦略的に Expert を目指すなら・・・

Kaggle Expert を目指すには「銅メダルを 2 つ以上取得」する必要がある。
あくまで興味を度外視して戦略的に Expert を目指すならば、「構造化データコンペ」を狙うのが最も効率的。
「構造化データコンペ」は GPU を必要としないものが多く、CPU で十分対応可能なため、Kaggle Notebook の無料枠で完結できることが多く、ローカル PC でも参加可能。

### メダルについて

Expert などのランクを目指すにはメダル獲得が必須となる。例えば、Expert になるには銅メダルを 2 つ以上取得する必要がある。
ただ、メダルが報酬となっているのは基本的に賞金付きコンペティションのみ。練習用コンペではメダルは付与されないと思われる。
また、賞金付きコンペかつ開催中かつ自分のできる専門領域に絞ると、そもそも参加できるコンペが非常に少なくなる。
報酬にメダルがあり、開催中でだれでも参加可能のコンペは[こちら](https://www.kaggle.com/competitions?listOption=active&prestigeFilter=medals&participationFilter=open)から確認可能。

## インフラ関係

**結論:**
最終的に一旦は Kaggle Notebook とローカルの API 連携を構築することになりそう。
Expert を目指すなら実行環境 Kaggle Notebook、コード管理はローカル GitHub が最も効率的。

### GPU の必要性について

銅メダルを取りやすいのは「構造化データコンペ」でこれらは CPU でも十分対応可能。例として、部屋数や築年数などの構造化データから住宅価格の予測行うコンペなどがこれに該当する。
GPU が本当に必要なのは「画像・NLP の深層学習コンペ」、[Natural Language Processing with Disaster Tweets](https://www.kaggle.com/competitions/nlp-getting-started/overview) 程度なら Kaggle Notebooks の無料 GPU で十分対応可能だが、それ以上となると有料プランの検討も必要になりそう。

| 環境                        | このコンペに適しているか                    |
| --------------------------- | ------------------------------------------- |
| **Kaggle Notebook（GPU）**  | ◎ 最適。大多数がこれ。                      |
| **Kaggle Notebook（CPU）**  | △ 遅いが不可能ではない。                    |
| **Google Colab（無料）**    | ○ 問題なく使えるが、Kaggle より連携が面倒。 |
| **クラウド GPU（GCP/AWS）** | ✗ オーバースペック。不要。                  |
| **ローカル PC（GPU なし）** | ✗ BERT などはつらい。Kaggle GPU で代替。    |

### Kaggle Notebook VS ローカル

**それぞれの特徴**

- **Kaggle Notebook**
  - 環境構築不要
  - 無料で GPU が使える
  - Kaggle データがそのまま使える
  - Submission がすぐ作れる
- **ローカル（VS Code）**
  - エディタが圧倒的に使いやすい
  - 複数ファイル構成に強い
  - デバッグがプロレベル
  - コード品質を高く保てる
  - 現場の ML 開発と同じ開発体験

**Kaggle Notebook とローカルのデータ連携**

- **Kaggle Dataset としてアップロード**
  - UI から簡単に Dataset 作成可能
  - 毎回 Dataset 更新がやや面倒
  - 更新反映にタイムラグがある
- **Kaggle API を使用してデータセットをダウンロード**
  - セットアップは手間
  - CLI で済むので楽、GitHub Actions 等にも組み込みやすい
  - 長期的には必須っぽく思える

### VSCode での .ipynb コード実行

ある程度の処理負荷であれば、拡張機能 Jupyter を使って VSCode 上で直接実行可能。
構造化データコンペやそれ以外でも前処理などの軽めの処理であれば VSCode 上で完結できるので、出力ファイルや保存目的で Kaggle にプッシュすればよさそう。

### 将来的なインフラ強化案

**Kaggle コンテナの使用**
Kaggle Notebook は Docker コンテナ上で動作しているため、将来的に同じコンテナをローカル PC 上で動かせれば、Kaggle と全く同じ環境でローカル開発が可能になる。
ただし、この [README](https://github.com/Kaggle/docker-python) のリンクにあるイメージをみると、イメージサイズは CPU 版でも 27GB と非常に大きい。

**GPU サーバーをつかったリモート開発**
今後 GPU を使った学習を VSCode 上で実行したい場合は Google Colab, Jupyter Lab (自前で GPU サーバー環境を用意) などが検討できそう。

**MLflow**
将来的に実験管理を行いたい場合は MLflow の導入も検討できそう。どうやら MLflow コンテナがあるらしい？

**その他**

- Kaggle の discussion を mcp で叩く
- AutoKaggle
- Kaggle-MCP

### Kaggle サーバーのディレクトリ

Kaggle Notebook 上で使用できるディレクトリ構成は以下の通り。
Kaggele サーバー上と同様のディレクトリアクセスを行うために、ディレクトリ構造を同じにしておく必要がある。

```
kaggle/
├── input/          ← コンペ・Dataset・自分のDatasetはここにマウント（read-only）
├── working/        ← 自由に書き込み可能（作業ディレクトリ）
├── temp/           ← 一時領域（書き込み可・高速・容量小）
├── src/            ← Save した Notebook のコード保存先
└── ...             ← OS標準のディレクトリ（usr, opt, etc）
```

**例:**

```python
# 例: Titanic データの読み込み
import pandas as pd
df = pd.read_csv("/kaggle/input/titanic/train.csv")

# 出力ファイルの保存
df.to_csv("/kaggle/working/submission.csv", index=False)

# 軽量な一時ファイルの保存
df.to_csv("/kaggle/temp/tempfile.csv", index=False)
```

### Kaggle サーバーのインストール済みライブラリ

Kaggle Notebook サーバーには多くのライブラリが最初からインストールされている。
詳細は[こちら](https://github.com/Kaggle/docker-python/blob/main/kaggle_requirements.txt)に記載されている。
numpy は記載がないが、これは Dockerfile 上に直接インストールされている模様。
よく使われるものだけ列挙すると以下の通り。

- numpy
- pandas
- scikit-learn
- matplotlib
- transformers
- tensorflow

## コンペの種類と使用技術

### 構造化データ（Tabular / Structured Data）

| 項目       | 内容                                                |
| ---------- | --------------------------------------------------- |
| 代表例     | Titanic / House Prices / TPS / Rossmann             |
| データ形式 | 数値、カテゴリ、日付、集計データ                    |
| 主なモデル | **LightGBM / XGBoost / CatBoost（ブースティング）** |
| 必要スキル | 特徴量エンジニアリング、EDA、バリデーション設計     |
| GPU 必要？ | **不要（CPU で十分）**                              |
| 難易度     | 初級〜中級                                          |

### NLP（自然言語処理）

| 項目       | 内容                                                  |
| ---------- | ----------------------------------------------------- |
| 代表例     | Tweet Disaster / Quora Insincere / Jigsaw             |
| データ形式 | テキスト（文章）、トークン列                          |
| 主なモデル | **BERT / RoBERTa / DistilBERT / LSTM / Transformers** |
| 必要スキル | トークナイズ、ファインチューニング、Embedding         |
| GPU 必要？ | **ほぼ必要（Transformer 学習のため）**                |
| 難易度     | 中級                                                  |

### 画像処理

| 項目       | 内容                                           |
| ---------- | ---------------------------------------------- |
| 代表例     | Dogs vs Cats / RSNA / SIIM-ISIC                |
| データ形式 | PNG/JPG 画像、マスク画像                       |
| 主なモデル | **ResNet / EfficientNet / ViT / YOLO / U-Net** |
| 必要スキル | CNN・データ拡張・画像前処理・GPU 最適化        |
| GPU 必要？ | **必須**（モデルも重い）                       |
| 難易度     | 中級～上級                                     |

## チーム機能

チームの組成はあくまで一つのコンペティションの中でのみ有効。GitHub であるような Organization アカウントのような形ではない。
各コンペティションページの「Team」タブから作成できる。

## WEB 版 Kaggle Notebook の基本操作

Kaggle Notebook の基本的な操作方法については[公式ドキュメント](https://www.kaggle.com/docs/notebooks)を参照のこと。

1. Kaggle の左メニューのプラスを押下し、「Notebook」を選択、エディタ等が開く
2. 右メニューの「Add Input」から参加したいコンペ名を検索て追加

## ipynb と py の違い

| 観点                      | `ipynb`（Jupyter Notebook）                      | `py`（Python スクリプト）                |
| ------------------------- | ------------------------------------------------ | ---------------------------------------- |
| **構造**                  | JSON 形式（コード＋出力＋ Markdown を保持）      | プレーンテキスト（Python コードのみ）    |
| **実行方式**              | セル単位で実行、状態を保持                       | ファイル全体を一括実行、状態は保持しない |
| **用途**                  | EDA、実験、プロトタイプ、教育、Kaggle            | 本番コード、ライブラリ、API、バッチ処理  |
| **再現性**                | ❌ セル順序依存で壊れやすい                      | ◎ 安定して再現可能                       |
| **可視化**                | ◎ 結果がそのまま埋め込まれる                     | △ 外部 UI またはログ出力が必要           |
| **ドキュメント性**        | ◎ Markdown 混在で説明しやすい                    | △ 別ファイル（README）必要               |
| **バージョン管理（Git）** | ❌ 差分が巨大・見づらい                          | ◎ 差分がきれいに管理できる               |
| **レビュー性**            | △ 実行状態に依存し理解しにくい                   | ◎ コードのみで明確                       |
| **パッケージ管理**        | `!pip install` で shell 経由                     | `pip install`（シェルから）              |
| **シェルの実行**          | `!ls`, `%%bash` など Magic で可                  | 通常は不可（subprocess が必要）          |
| **学習コスト**            | 低い（直感的）                                   | やや高い（構造化が必要）                 |
| **速度**                  | 基本同じだが Notebook は状態保持で重くなりやすい | 同じだが軽量                             |
| **エコシステム**          | Kaggle / Colab / JupyterLab                      | ほぼ全 Python 環境で利用可能             |
| **本番運用**              | 不向き                                           | 向いている                               |

```json
{
  // Notebook の全セル（コード / Markdown / 出力）
  "cells": [
    {
      // Markdown セル
      "cell_type": "markdown",
      "metadata": {},
      "source": ["# これは説明用の Markdown セルです。"]
    },
    {
      // コードセル
      "cell_type": "code",
      // セルが何回目に実行されたか（未実行なら null）
      "execution_count": 1,
      // コード本体（文字列リスト）
      "source": ["print('Hello, world!')\n", "x = 42\n", "x"],
      // セル実行後の出力（複数ありうる）
      "outputs": [
        {
          // stdout 出力
          "output_type": "stream",
          "name": "stdout",
          "text": ["Hello, world!\n"]
        },
        {
          // 最後に評価された値（Jupyter が自動表示するもの）
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": ["42"]
          }
        }
      ]
    }
  ],

  // Notebook 全体のメタ情報
  "metadata": {
    // 使用するカーネルの情報
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },

    // 言語自体の仕様情報（バージョン / 拡張子など）
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },

  // Notebook ファイルフォーマットのバージョン
  "nbformat": 4,
  "nbformat_minor": 5
}
```

## 機械学習フレームワークについて

### フレームワーク比較表

主要な機械学習フレームワークの特徴比較は以下の通り。
なお、transformers ライブラリは PyTorch / TensorFlow のラッパーであり、NLP タスクに特化したものなので、ここでは除外している。

|              | **PyTorch**            | **TensorFlow**        | **Keras**              | **scikit-learn**   |
| ------------ | ---------------------- | --------------------- | ---------------------- | ------------------ |
| **分類**     | 深層学習               | 深層学習              | 深層学習の高レベル API | 伝統的機械学習     |
| **用途**     | 画像/NLP/研究          | 本番運用/大規模 DL    | 簡易 DL 構築           | 回帰/分類/前処理   |
| **特徴**     | 書きやすい・研究に強い | Google 製・運用に強い | 直感的で簡単           | 軽量・高速         |
| **GPU**      | 対応                   | 対応                  | TensorFlow 依存        | 非対応（基本 CPU） |
| **得意分野** | BERT/GPT など最新 NLP  | モバイル/TPU/大規模   | 初学者向け DL          | SVM, RF, ロジ回帰  |
| **併用**     | TF と併用しない        | PyTorch と併用しない  | TensorFlow とセット    | 深層学習と併用あり |

### 併用について

| 組み合わせ                    | 併用する？ | コメント                   |
| ----------------------------- | ---------- | -------------------------- |
| **PyTorch × TensorFlow**      | ❌ しない  | 役割が競合するため         |
| **Keras × TensorFlow**        | ◎ 常に使う | `tf.keras` が標準          |
| **scikit-learn × PyTorch**    | ◎ よく使う | テキスト前処理・分割など   |
| **scikit-learn × TensorFlow** | ◎ よく使う | パイプラインとの連携が容易 |

### 推奨フレームワーク

NLP Getting Started コンペでの推奨は以下。

**初級：scikit-learn**

- 実装パターン
  - TF-IDF + ロジスティック回帰
  - TF-IDF + SVM
- メリット
  - ランタイムが速い
  - 実装が容易
  - 小データではむしろ強い
- サンプル
  - https://www.kaggle.com/code/philculliton/nlp-getting-started-tutorial
  - スコア 0.78179

**中級：TensorFlow/Keras or PyTorch（自作 NN）**

- 実装パターン
  - LSTM
  - GRU
  - 1D CNN
- メリット
  - 柔軟にモデル設計可能
  - 最近はこれらは非主流だが、学習目的では良い
- サンプル
  - https://www.kaggle.com/code/berkayzkan/rank-8-solution-roberta-large
  - スコア 0.83634

**上級：TensorFlow/PyTorch + Hugging Face Transformers**

- 実装パターン
  - BERT
  - RoBERTa
  - DistilBERT
- メリット
  - 精度最強
- サンプル
  - https://www.kaggle.com/code/dhruv1234/huggingface-tfbertmodel
  - スコア 0.84523
