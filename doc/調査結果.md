# 調査結果

Expert を目指すにあたり必要な諸々について簡単に調査した結果をまとめる。

## Kaggle のランク制度と外部評価

### 外部評価

正直 Master 以上でない限り、基本的には「取り組み」レベルでしか評価されなさそう。
逆に Master 以上になると、条件として明記されるようになり、組織側が「弊社には〇人います」といったアピールもするようになるらしい。
ただ、「自然言語処理での Kaggle 受賞歴」、「分析コンペでのメダル獲得経験」などを評価点として明記している組織はある。

### あくまで戦略的に Expert を目指すなら・・・

Kaggle Expert を目指すには「銅メダルを 2 つ以上取得」する必要がある。
あくまで興味を度外視して戦略的に Expert を目指すならば、「構造化データコンペ」を狙うのが最も効率的。
「構造化データコンペ」は GPU を必要としないものが多く、CPU で十分対応可能なため、Kaggle Notebook の無料枠で完結できることが多く、ローカル PC でも参加可能。

### メダルについて

Expert などのランクを目指すにはメダル獲得が必須となる。例えば、Expert になるには銅メダルを 2 つ以上取得する必要がある。
ただ、メダルが報酬となっているのは基本的に賞金付きコンペティションのみ。練習用コンペではメダルは付与されないと思われる。
また、賞金付きコンペかつ開催中かつ自分のできる専門領域に絞ると、そもそも参加できるコンペが非常に少なくなる。
報酬にメダルがあり、開催中でだれでも参加可能のコンペは[こちら](https://www.kaggle.com/competitions?listOption=active&prestigeFilter=medals&participationFilter=open)から確認可能。

## インフラ関係

### GPU の必要性について

**結論:**
最終的に一旦は Kaggle Notebook とローカルの API 連携を構築することになりそう。

銅メダルを取りやすいのは「構造化データコンペ」でこれらは CPU でも十分対応可能。例として、部屋数や築年数などの構造化データから住宅価格の予測行うコンペなどがこれに該当する。
GPU が本当に必要なのは「画像・NLP の深層学習コンペ」、[Natural Language Processing with Disaster Tweets](https://www.kaggle.com/competitions/nlp-getting-started/overview) 程度なら Kaggle Notebooks の無料 GPU で十分対応可能だが、それ以上となると有料プランの検討も必要になりそう。

| 環境                        | このコンペに適しているか                    |
| --------------------------- | ------------------------------------------- |
| **Kaggle Notebook（GPU）**  | ◎ 最適。大多数がこれ。                      |
| **Kaggle Notebook（CPU）**  | △ 遅いが不可能ではない。                    |
| **Google Colab（無料）**    | ○ 問題なく使えるが、Kaggle より連携が面倒。 |
| **クラウド GPU（GCP/AWS）** | ✗ オーバースペック。不要。                  |
| **ローカル PC（GPU なし）** | ✗ BERT などはつらい。Kaggle GPU で代替。    |

### Kaggle Notebook VS ローカル

**結論:**
Expert を目指すなら実行環境 Kaggle Notebook、コード管理はローカル GitHub が最も効率的。
Kaggle 上位勢はほぼ全員やっているっぽい。

**それぞれの特徴**

- **Kaggle Notebook**
  - 環境構築不要
  - 無料で GPU が使える
  - Kaggle データがそのまま使える
  - Submission がすぐ作れる
- **ローカル（VS Code）**
  - エディタが圧倒的に使いやすい
  - 複数ファイル構成に強い
  - デバッグがプロレベル
  - コード品質を高く保てる
  - 現場の ML 開発と同じ開発体験

**Kaggle Notebook とローカルのデータ連携**

- **Kaggle Dataset としてアップロード**
  - UI から簡単に Dataset 作成可能
  - 毎回 Dataset 更新がやや面倒
  - 更新反映にタイムラグがある
- **Kaggle API を使用してデータセットをダウンロード**
  - セットアップは手間
  - CLI で済むので楽、GitHub Actions 等にも組み込みやすい
  - 長期的には必須っぽく思える

### VSCode での .ipynb コード実行

ある程度の処理負荷であれば、拡張機能 Jupyter を使って VSCode 上で直接実行可能。
構造化データコンペやそれ以外でも前処理などの軽めの処理であれば VSCode 上で完結できるので、出力ファイルや保存目的で Kaggle にプッシュすればよさそう。
ただ、今後 GPU を使った学習を VSCode 上で実行したい場合は Google Colab, Jupyter Lab (自前で GPU サーバー環境を用意) などを検討する必要がある。

## コンペの種類と使用技術

### 構造化データ（Tabular / Structured Data）

| 項目       | 内容                                                |
| ---------- | --------------------------------------------------- |
| 代表例     | Titanic / House Prices / TPS / Rossmann             |
| データ形式 | 数値、カテゴリ、日付、集計データ                    |
| 主なモデル | **LightGBM / XGBoost / CatBoost（ブースティング）** |
| 必要スキル | 特徴量エンジニアリング、EDA、バリデーション設計     |
| GPU 必要？ | **不要（CPU で十分）**                              |
| 難易度     | 初級〜中級                                          |

### NLP（自然言語処理）

| 項目       | 内容                                                  |
| ---------- | ----------------------------------------------------- |
| 代表例     | Tweet Disaster / Quora Insincere / Jigsaw             |
| データ形式 | テキスト（文章）、トークン列                          |
| 主なモデル | **BERT / RoBERTa / DistilBERT / LSTM / Transformers** |
| 必要スキル | トークナイズ、ファインチューニング、Embedding         |
| GPU 必要？ | **ほぼ必要（Transformer 学習のため）**                |
| 難易度     | 中級                                                  |

### 画像処理

| 項目       | 内容                                           |
| ---------- | ---------------------------------------------- |
| 代表例     | Dogs vs Cats / RSNA / SIIM-ISIC                |
| データ形式 | PNG/JPG 画像、マスク画像                       |
| 主なモデル | **ResNet / EfficientNet / ViT / YOLO / U-Net** |
| 必要スキル | CNN・データ拡張・画像前処理・GPU 最適化        |
| GPU 必要？ | **必須**（モデルも重い）                       |
| 難易度     | 中級～上級                                     |

## チーム機能

チームの組成はあくまで一つのコンペティションの中でのみ有効。GitHub であるような Organization アカウントのような形ではない。
各コンペティションページの「Team」タブから作成できる。

## WEB 版 Kaggle Notebook の基本操作

Kaggle Notebook の基本的な操作方法については[公式ドキュメント](https://www.kaggle.com/docs/notebooks)を参照のこと。

1. Kaggle の左メニューのプラスを押下し、「Notebook」を選択、エディタ等が開く
2. 右メニューの「Add Input」から参加したいコンペ名を検索て追加

## Kaggle サーバーのディレクトリ

Kaggle Notebook 上で使用できるディレクトリ構成は以下の通り。
Kaggele サーバー上と同様のディレクトリアクセスを行うために、ディレクトリ構造を同じにしておく必要がある。

```
kaggle/
├── input/          ← コンペ・Dataset・自分のDatasetはここにマウント（read-only）
├── working/        ← 自由に書き込み可能（作業ディレクトリ）
├── temp/           ← 一時領域（書き込み可・高速・容量小）
├── src/            ← Save した Notebook のコード保存先
└── ...             ← OS標準のディレクトリ（usr, opt, etc）
```

**例:**

```python
# 例: Titanic データの読み込み
import pandas as pd
df = pd.read_csv("/kaggle/input/titanic/train.csv")

# 出力ファイルの保存
df.to_csv("/kaggle/working/submission.csv", index=False)

# 軽量な一時ファイルの保存
df.to_csv("/kaggle/temp/tempfile.csv", index=False)
```
