# 技術的な知識

本ドキュメントでは、機械学習やそれに関連する技術的な知識についてまとめる。

## ipynb と py の違い

| 観点                      | `ipynb`（Jupyter Notebook）                      | `py`（Python スクリプト）                |
| ------------------------- | ------------------------------------------------ | ---------------------------------------- |
| **構造**                  | JSON 形式（コード＋出力＋ Markdown を保持）      | プレーンテキスト（Python コードのみ）    |
| **実行方式**              | セル単位で実行、状態を保持                       | ファイル全体を一括実行、状態は保持しない |
| **用途**                  | EDA、実験、プロトタイプ、教育、Kaggle            | 本番コード、ライブラリ、API、バッチ処理  |
| **再現性**                | ❌ セル順序依存で壊れやすい                      | ◎ 安定して再現可能                       |
| **可視化**                | ◎ 結果がそのまま埋め込まれる                     | △ 外部 UI またはログ出力が必要           |
| **ドキュメント性**        | ◎ Markdown 混在で説明しやすい                    | △ 別ファイル（README）必要               |
| **バージョン管理（Git）** | ❌ 差分が巨大・見づらい                          | ◎ 差分がきれいに管理できる               |
| **レビュー性**            | △ 実行状態に依存し理解しにくい                   | ◎ コードのみで明確                       |
| **パッケージ管理**        | `!pip install` で shell 経由                     | `pip install`（シェルから）              |
| **シェルの実行**          | `!ls`, `%%bash` など Magic で可                  | 通常は不可（subprocess が必要）          |
| **学習コスト**            | 低い（直感的）                                   | やや高い（構造化が必要）                 |
| **速度**                  | 基本同じだが Notebook は状態保持で重くなりやすい | 同じだが軽量                             |
| **エコシステム**          | Kaggle / Colab / JupyterLab                      | ほぼ全 Python 環境で利用可能             |
| **本番運用**              | 不向き                                           | 向いている                               |

```json
{
  // Notebook の全セル（コード / Markdown / 出力）
  "cells": [
    {
      // Markdown セル
      "cell_type": "markdown",
      "metadata": {},
      "source": ["# これは説明用の Markdown セルです。"]
    },
    {
      // コードセル
      "cell_type": "code",
      // セルが何回目に実行されたか（未実行なら null）
      "execution_count": 1,
      // コード本体（文字列リスト）
      "source": ["print('Hello, world!')\n", "x = 42\n", "x"],
      // セル実行後の出力（複数ありうる）
      "outputs": [
        {
          // stdout 出力
          "output_type": "stream",
          "name": "stdout",
          "text": ["Hello, world!\n"]
        },
        {
          // 最後に評価された値（Jupyter が自動表示するもの）
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": ["42"]
          }
        }
      ]
    }
  ],

  // Notebook 全体のメタ情報
  "metadata": {
    // 使用するカーネルの情報
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },

    // 言語自体の仕様情報（バージョン / 拡張子など）
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },

  // Notebook ファイルフォーマットのバージョン
  "nbformat": 4,
  "nbformat_minor": 5
}
```

## 機械学習フレームワークについて

### フレームワーク比較表

主要な機械学習フレームワークの特徴比較は以下の通り。
なお、transformers ライブラリは PyTorch / TensorFlow のラッパーであり、NLP タスクに特化したものなので、ここでは除外している。

|              | **PyTorch**            | **TensorFlow**        | **Keras**              | **scikit-learn**   |
| ------------ | ---------------------- | --------------------- | ---------------------- | ------------------ |
| **分類**     | 深層学習               | 深層学習              | 深層学習の高レベル API | 伝統的機械学習     |
| **用途**     | 画像/NLP/研究          | 本番運用/大規模 DL    | 簡易 DL 構築           | 回帰/分類/前処理   |
| **特徴**     | 書きやすい・研究に強い | Google 製・運用に強い | 直感的で簡単           | 軽量・高速         |
| **GPU**      | 対応                   | 対応                  | TensorFlow 依存        | 非対応（基本 CPU） |
| **得意分野** | BERT/GPT など最新 NLP  | モバイル/TPU/大規模   | 初学者向け DL          | SVM, RF, ロジ回帰  |
| **併用**     | TF と併用しない        | PyTorch と併用しない  | TensorFlow とセット    | 深層学習と併用あり |

### 併用について

| 組み合わせ                    | 併用する？ | コメント                   |
| ----------------------------- | ---------- | -------------------------- |
| **PyTorch × TensorFlow**      | ❌ しない  | 役割が競合するため         |
| **Keras × TensorFlow**        | ◎ 常に使う | `tf.keras` が標準          |
| **scikit-learn × PyTorch**    | ◎ よく使う | テキスト前処理・分割など   |
| **scikit-learn × TensorFlow** | ◎ よく使う | パイプラインとの連携が容易 |

### 推奨フレームワーク

NLP Getting Started コンペでの推奨は以下。

**初級：scikit-learn**

- 実装パターン
  - TF-IDF + ロジスティック回帰
  - TF-IDF + SVM
- メリット
  - ランタイムが速い
  - 実装が容易
  - 小データではむしろ強い
- サンプル
  - https://www.kaggle.com/code/philculliton/nlp-getting-started-tutorial
  - スコア 0.78179

**中級：TensorFlow/Keras or PyTorch（自作 NN）**

- 実装パターン
  - LSTM
  - GRU
  - 1D CNN
- メリット
  - 柔軟にモデル設計可能
  - 最近はこれらは非主流だが、学習目的では良い
- サンプル
  - https://www.kaggle.com/code/berkayzkan/rank-8-solution-roberta-large
  - スコア 0.83634

**上級：TensorFlow/PyTorch + Hugging Face Transformers**

- 実装パターン
  - BERT
  - RoBERTa
  - DistilBERT
- メリット
  - 精度最強
- サンプル
  - https://www.kaggle.com/code/dhruv1234/huggingface-tfbertmodel
  - スコア 0.84523

## 言語仕様、補助的ライブラリ・ツール

### リスト/タプル/セットの違い

| 観点               | リスト（list）         | タプル（tuple）        | セット（set）                    |
| ------------------ | ---------------------- | ---------------------- | -------------------------------- |
| **構造**           | 可変長、順序・重複あり | 不変長、順序・重複あり | 順序・重複なし                   |
| **変更可能性**     | 追加・削除・変更が可能 | 追加・削除・変更が不可 | 追加・削除は可能                 |
| **用途**           | データの集約・操作     | 定数・固定データの保持 | 重複除去に便利                   |
| **パフォーマンス** | やや遅い               | やや速い               | 高速（検索が速い）               |
| **メモリ使用量**   | 多い                   | 少ない                 | 中程度                           |
| **シンタックス**   | 角括弧 `[]`            | 丸括弧 `()`            | 波括弧 `{}` （空集合は `set()`） |

### pandas

データ操作ライブラリ。構造化データコンペではほぼ必須。雑にいうと SQL ライクなデータ操作を Python 上で可能にするライブラリ。データフレームは同じデータ型を強要しないが、単一のカラムだけを抽出したものといえるシリーズは同じデータ型を強要する。

[公式ドキュメント](https://pandas.pydata.org/docs/reference/frame.html)。見やすく例も充実している印象。

| カテゴリ   | 関数・属性                 | 概要と主な用途                                                                      |
| :--------- | :------------------------- | :---------------------------------------------------------------------------------- |
| **入出力** | `pd.read_csv()`            | CSV ファイルを DataFrame として読み込む。最も頻繁に使われる入力関数。               |
|            | `df.to_csv()`              | DataFrame の内容を CSV ファイルとして出力する。                                     |
| **確認**   | `df.head()` / `df.tail()`  | DataFrame の先頭（デフォルト 5 行）または末尾の行を表示し、データの概要を把握する。 |
|            | `df.info()`                | 各列のデータ型（Dtype）、非 null 値の数、メモリ使用量などの詳細情報を表示する。     |
|            | `df.describe()`            | 数値列の統計的要約（平均、標準偏差、最小・最大値、四分位数など）を計算する。        |
|            | `df['col'].value_counts()` | 指定した列（`'col'`）に含まれる一意な値の出現回数をカウントする。                   |
| **抽出**   | `df['col']`                | 特定の列（Series）を選択する。                                                      |
|            | `df.loc[]` / `df.iloc[]`   | 行と列を、ラベル名（`.loc`）または整数位置（`.iloc`）で選択する。                   |
|            | `df[df['col'] > 10]`       | 条件に基づいて行をフィルタリング（抽出）する。                                      |
| **整形**   | `df.dropna()`              | 欠損値（NaN）を含む行または列を削除する。                                           |
|            | `df.fillna()`              | 欠損値を特定の値（例：0 や平均値）で埋める。                                        |
|            | `df.rename()`              | 列名やインデックス名を変更する。                                                    |
| **集計**   | `df.groupby('col').mean()` | 特定の列（`'col'`）でグループ化し、グループごとに平均などの集計関数を適用する。     |
|            | `df.pivot_table()`         | Excel のピボットテーブルのようにデータを集計・再構成する。                          |
| **結合**   | `pd.merge()`               | 複数の DataFrame を、共通の列をキーとして結合（JOIN）する。                         |
|            | `pd.concat()`              | 複数の DataFrame を、縦（行）または横（列）に連結する。                             |

### NumPy

行列演算を中心とした数学的な演算処理に使うライブラリ。全ての要素が同じデータ型をもつ点で、Python 標準のリストなどと異なる。内部で C の資産を使用しており実行が速く、標準のリストより直感的な行列計算を使用できる。

[公式ドキュメント](https://numpy.org/doc/stable/reference/arrays.ndarray.html)。見やすいがちょっと小難しいかも。

| カテゴリ     | 関数・属性                               | 概要と主な用途                                                         |
| :----------- | :--------------------------------------- | :--------------------------------------------------------------------- |
| **配列生成** | `np.array([..])`                         | Python のリストやタプルから`ndarray`を生成する。                       |
|              | `np.zeros(shape)` / `np.ones(shape)`     | 全てが 0 または 1 の指定した形状（`shape`）の配列を生成する。          |
|              | `np.arange(start, stop, step)`           | 指定範囲で等差数列を生成する。                                         |
|              | `np.linspace(start, stop, num)`          | 指定範囲を均等に分割した要素を持つ配列を生成する。                     |
|              | `np.random.rand()` / `np.random.randn()` | 乱数で配列を生成する（機械学習の重み初期化などで多用）。               |
| **形状操作** | `array.shape`                            | 配列の形状（タプル）を取得する。                                       |
|              | `array.reshape(new_shape)`               | 配列の要素数を変えずに形状を変更する。                                 |
|              | `array.T` / `np.transpose(array)`        | 配列を転置（行と列を入れ替え）する。行列計算の際に頻繁に使う。         |
| **集計**     | `np.sum(array, axis=...)`                | 配列内の要素の合計を計算する。`axis`指定で行/列方向の合計も可能。      |
|              | `np.mean()`, `np.std()`                  | 配列内の要素の平均、標準偏差などを計算する。                           |
|              | `np.dot(a, b)` / `a @ b`                 | 配列 a と b の行列積（内積）を計算する。機械学習の基盤となる演算。     |
| **演算**     | `np.exp()`, `np.log()`, `np.sqrt()`      | 配列の各要素に対して、指数関数、対数、平方根などの数学関数を適用する。 |
|              | `array > 5`                              | 配列の各要素に対して条件判定を行い、真偽値（True/False）の配列を返す。 |

## !pip install と %pip install の違い

**結論:** 基本的に `%pip install` を使う ([参考](https://www.kaggle.com/code/matinmahmoudi/complete-guide-to-pip-commands-a-to-z))

### !pip

`!` は「シェルコマンド実行」のための IPython 構文。`!pip install xxx` は Python カーネル（実行環境）とは無関係にシェル上で pip が実行されるので、以下が起こりうる。

```python
!pip install numpy
import numpy  # インポートエラー
```

### %pip

`%` は「マジックコマンド実行」のための IPython 構文。`%pip install xxx` は現在の Python カーネル（実行環境）に紐づいた pip が実行されるので、上記のような問題が起こらない。

## ipynb の import

重要な基本として、ipynb ファイルをモジュールとして import することはできない。基本的に再利用するコードは py ファイルとして保存し、ipynb から import して使う。

### 独自モジュールの import

Notebook は一度インポートしたモジュールをキャッシュするため、my_module.py のコードを書き換えて保存しても、Notebook 側のセルを再実行するだけでは変更が反映されない。カーネル（実行プロセス）再起動が必要。
自動リロードを有効にするマジックコマンドを入れておくと、my_module.py のコードを書き換えて保存した際に自動的に再インポートされるようになる。

```python
%load_ext autoreload
%autoreload 2

import my_module
```

## 簡単にしか調べてないこと

##
