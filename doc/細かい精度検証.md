# 細かい精度検証

本ドキュメントでは、モデルの精度に関する細かい検証結果と、変更点をまとめます。
実行コマンド: `uv run python kaggle/src/main.py`

## スコアの推移

**最初の実装**
交差検証スコア: [0.68548917 0.54629022 0.54694682 0.61498029 0.65900131]
精度平均: 0.61054156

**replace_links の置換を URLTEXT に変更**
交差検証スコア: [0.68483257 0.56007879 0.54038083 0.60643890 0.66228647]
精度平均: 0.61080351
処理時間: 74.40 秒
-> 精度微増、**適用する**

**TfidfVectorizer の max_features を 4000 に変更**
交差検証スコア: [0.67760998 0.54103743 0.53512804 0.60183968 0.66228647]
精度平均: 0.60358032
-> 精度低下、適用しない

**TfidfVectorizer の max_features を 2000 に変更**
交差検証スコア: [0.68548917 0.54169402 0.53709783 0.61366623 0.66819974]
精度平均: 0.60922940
-> 精度低下、適用しない

**TfidfVectorizer の max_features を 500 に変更**
交差検証スコア: [0.67432699 0.55154301 0.53578464 0.61695138 0.67214192]
精度平均: 0.61014959
処理時間: 61.56 秒
-> 精度微低下の割に計算が速い、**適用する**

**keyword のカウント時に足切り (min_df=20) を導入**
交差検証スコア: [0.67367039 0.55876559 0.53447144 0.62220762 0.67148489]
精度平均: 0.61211999
処理時間: 66.97 秒
-> 精度微増、**適用する**

**location のカウント時に足切り (min_count=20) を導入**
交差検証スコア: [0.6690742  0.554826   0.53644123 0.60906702 0.66688568]
精度平均: 0.60725883
処理時間: 60.24 秒
-> 精度低下、適用しない

**location のカウント時に足切り (min_count=10) を導入**
交差検証スコア: [0.67235719 0.558109   0.54366382 0.62286465 0.66031537]
精度平均: 0.61146201
処理時間: 59.84 秒
-> 精度微増、**適用する**

**location のカウント時に足切り (min_count=5) を導入**
交差検証スコア: [0.67301379 0.5567958  0.52987525 0.60775296 0.66622865]
精度平均: 0.60673329
処理時間: 63.14 秒
-> 精度低下、適用しない

**keyword のカウント時に足切り (min_df=10) を導入**
交差検証スコア: [0.6690742  0.5554826  0.53512804 0.61826544 0.67674113]
精度平均: 0.61093828
処理時間: 59.37 秒
-> 精度低下、適用しない

**keyword のカウント時に足切り (min_df=30) を導入**
交差検証スコア: [0.62705187 0.5567958  0.52856205 0.62417871 0.67214192]
精度平均: 0.60174607
処理時間: 60.79 秒
-> 精度低下、適用しない

**学習・評価処理での並列処理を有効化**
交差検証スコア: [0.67235719 0.558109   0.54366382 0.62286465 0.66031537]
精度平均: 0.61146201
処理時間: 48.65 秒
-> 処理時間大幅短縮、**適用する**

**メンションを削除ではなく、置換に変更**
交差検証スコア: [0.68023638 0.56073539 0.53250164 0.63731932 0.67542707]
精度平均: 0.61724396
処理時間: 45.61 秒
-> 精度微増、**適用する**

**countries.search_fuzzy の結果キャッシュを有効化**
交差検証スコア: [0.68023638 0.56073539 0.53250164 0.63731932 0.67542707]
精度平均: 0.61724396
処理時間: 23.75 秒
-> 処理時間大幅短縮、**適用する**

**RandomForestClassifier > class_weight="balanced"**
交差検証スコア: [0.66776100 0.55942219 0.53709783 0.63272011 0.68659658]
精度平均: 0.61671954
処理時間: 23.36 秒
-> 精度低下、適用しない

**RandomForestClassifier > max_depth=15**
交差検証スコア: [0.65134603 0.58765594 0.60275772 0.62746386 0.69645204]
精度平均: 0.63313512
処理時間: 21.49 秒
-> 精度大幅向上、**適用する**


## AI 君の助言

実装と結果の推移を確認しました。精度が向上しない、あるいは低下している主な原因として、以下の 3 点が考えられます。

### 前処理による情報の欠落（過剰な正規化）

特に `v2` 以降で顕著ですが、**「正規化しすぎて重要な情報が消えている」** 可能性があります。

- **Location の正規化**:
  `pycountry` で国名に丸めていますが、災害ツイートにおいて「国」単位では粒度が粗すぎる可能性があります（例: "California" と "Texas" は同じ "United States" になってしまう）。災害は局所的なイベントなので、州や都市の情報が重要かもしれません。
- **Keyword のステミング**:
  `v4` で導入したステミング（例: "burning" -> "burn"）は、語形変化を同一視できる反面、文脈によるニュアンスの違い（「燃えている」vs「火傷」）を消してしまうリスクがあります。

### 特徴量の次元数とスパース性

- **Keyword/Location の One-Hot Encoding**:
  これらは非常にスパース（スカスカ）な行列になります。RandomForest は決定木の集合体なので、スパースな特徴量が多いと、重要な特徴量（TF-IDF など）が埋もれてしまい、分割の効率が悪くなることがあります。

### モデルのパラメータ調整不足

- **RandomForest のデフォルト設定**:
  `RandomForestClassifier(random_state=42)` のまま使用していますが、特徴量の性質（次元数、スパース性）が大きく変わっているのに、モデルのパラメータ（木の深さ `max_depth`、最小サンプル数 `min_samples_split` など）がそのままだと、モデルがデータに適合できていない可能性があります。特に `v1` で本番スコアが激減したのは、過学習（Overfitting）または未学習（Underfitting）の兆候です。

---

### 今後の改善案

1.  **Location の見直し**:
    国名への正規化をやめ、単純な `CountVectorizer` (Top N 件) に戻すか、正規化前のデータも特徴量として残す。
2.  **TF-IDF の次元数増加**:
    `max_features` を 3000〜5000 程度に増やしてみる。
3.  **モデルの変更**:
    スパースなテキストデータに強い **LinearSVC** や **Naive Bayes**、あるいは勾配ブースティング（**LightGBM**, **XGBoost**）を試す。
4.  **特徴量の重要度確認**:
    `clf.feature_importances_` を確認し、苦労して作った `location` や `keyword` が実際にモデルに使われているか確認する（もし寄与度が低ければ、前処理の方向性が間違っている）。

まずは **「特徴量の重要度 (Feature Importance) の確認」** から始めることを強くお勧めします。モデルが何を見て判断しているかを知ることで、どの前処理が有効か（あるいは無駄か）が見えてくるはずです。

## 圧倒的に精度を向上させるには

- BERT などの事前学習済み言語モデルを使う
- keyword も word2vec や FastText でベクトル化する
- Location をジオコーディングして緯度経度情報などに変換する
