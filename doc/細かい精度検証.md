# 最初

**最初の実装**
交差検証スコア: [0.68548917 0.54629022 0.54694682 0.61498029 0.65900131]
精度平均: 0.61054156

**replace_links の置換を URLTEXT に変更**
交差検証スコア: [0.68483257 0.56007879 0.54038083 0.6064389 0.66228647]
精度平均: 0.61080351
-> 精度微増、適用する

## AI 君の助言

実装と結果の推移を確認しました。精度が向上しない、あるいは低下している主な原因として、以下の 3 点が考えられます。

### 前処理による情報の欠落（過剰な正規化）

特に `v2` 以降で顕著ですが、**「正規化しすぎて重要な情報が消えている」** 可能性があります。

- **Location の正規化**:
  `pycountry` で国名に丸めていますが、災害ツイートにおいて「国」単位では粒度が粗すぎる可能性があります（例: "California" と "Texas" は同じ "United States" になってしまう）。災害は局所的なイベントなので、州や都市の情報が重要かもしれません。
- **Text のリンク削除**:
  `[LINK_URL]` への置換 (`v1`) から完全削除 (`v2`) に変更されていますが、リンクがあること自体が「情報の信頼性」や「ニュース性」を表す特徴量になる可能性があります。
- **Keyword のステミング**:
  `v4` で導入したステミング（例: "burning" -> "burn"）は、語形変化を同一視できる反面、文脈によるニュアンスの違い（「燃えている」vs「火傷」）を消してしまうリスクがあります。

### 特徴量の次元数とスパース性

- **TF-IDF の `max_features=1000`**:
  語彙数が数千〜数万ある中で 1000 に制限しているため、前処理で正規化しても、そもそもモデルに入力される単語セットがあまり変わっていない（上位 1000 語は常に似たような単語）可能性があります。
- **Keyword/Location の One-Hot Encoding**:
  これらは非常にスパース（スカスカ）な行列になります。RandomForest は決定木の集合体なので、スパースな特徴量が多いと、重要な特徴量（TF-IDF など）が埋もれてしまい、分割の効率が悪くなることがあります。

### モデルのパラメータ調整不足

- **RandomForest のデフォルト設定**:
  `RandomForestClassifier(random_state=42)` のまま使用していますが、特徴量の性質（次元数、スパース性）が大きく変わっているのに、モデルのパラメータ（木の深さ `max_depth`、最小サンプル数 `min_samples_split` など）がそのままだと、モデルがデータに適合できていない可能性があります。特に `v1` で本番スコアが激減したのは、過学習（Overfitting）または未学習（Underfitting）の兆候です。

---

### 今後の改善案

1.  **Location の見直し**:
    国名への正規化をやめ、単純な `CountVectorizer` (Top N 件) に戻すか、正規化前のデータも特徴量として残す。
2.  **TF-IDF の次元数増加**:
    `max_features` を 3000〜5000 程度に増やしてみる。
3.  **モデルの変更**:
    スパースなテキストデータに強い **LinearSVC** や **Naive Bayes**、あるいは勾配ブースティング（**LightGBM**, **XGBoost**）を試す。
4.  **特徴量の重要度確認**:
    `clf.feature_importances_` を確認し、苦労して作った `location` や `keyword` が実際にモデルに使われているか確認する（もし寄与度が低ければ、前処理の方向性が間違っている）。

まずは **「特徴量の重要度 (Feature Importance) の確認」** から始めることを強くお勧めします。モデルが何を見て判断しているかを知ることで、どの前処理が有効か（あるいは無駄か）が見えてくるはずです。
